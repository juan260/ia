{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Práctica 5 de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construcción de clasificadores en bases de datos sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esta primera parte está adaptada de:\n",
    "# http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.datasets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ceffe08fd8be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_moons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_circles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.datasets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "simple = make_blobs(n_samples=500, n_features=2,\n",
    "                    centers=[[0,0], [2.5,2.5]],\n",
    "                    random_state=1)\n",
    "X,y = make_blobs(n_samples=500, n_features=2,\n",
    "                 centers=[[0,0], [5,1]],\n",
    "                 random_state=1)\n",
    "X = X*np.matrix([[1,-2],[-20,10]])\n",
    "linearly_separable=(X,y)\n",
    "\n",
    "datasets = [simple,\n",
    "            linearly_separable,\n",
    "            make_moons(noise=0.1, random_state=0, n_samples=500),\n",
    "            make_circles(noise=0.1, factor=0.5, random_state=1,\n",
    "                         n_samples=500)\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [(\"Naive Bayes\", GaussianNB()),\n",
    "               (\"Nearest Neighbors\",\n",
    "                KNeighborsClassifier(n_neighbors=1)), # número de vecinos\n",
    "               (\"Decision Tree\",\n",
    "                DecisionTreeClassifier(criterion='entropy',\n",
    "                                       max_depth=2)), # profundidad máxima del árbol\n",
    "               (\"Logistic Regression\",\n",
    "                LogisticRegression(C=1e10)), # C: cuanto más alto menos regularización \n",
    "               (\"Neural Network\",\n",
    "                MLPClassifier(hidden_layer_sizes=(50,), # tamaño capas ocultas\n",
    "                              max_iter=1000, # número máximo de iteraciones\n",
    "                              alpha=0))] # factor de regularización\n",
    "\n",
    "from p5_IA_aux import plot_classifiers\n",
    "\n",
    "plot_classifiers(classifiers, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Listado de los parámetros de los diferentes clasificadores\n",
    "for name, clf in classifiers:\n",
    "    print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba a cambiar los siguientes parámetros y observa las consecuencias en la frontera de clasificación construida:\n",
    "\n",
    "* Número de vecinos en k-nn: Prueba a ir subiendo este número. ¿Por qué siempre debe ser impar cuando hay dos clases?\n",
    "* Profundidad máxima de los árboles de decisión: Prueba a ir subiendo este número.\n",
    "* Factor de regularización (C) en la regresión logística: prueba C=1e10, C=1 y C=1e-7.\n",
    "* Número de neuronas en la red neuronal y máximo número de épocas de entrenamiento. ** Nota: ** (50,) indica una única capa oculta con 50 neuronas. Prueba a reducir este número. También puedes probar a introducir más de una capa oculta. Por ejemplo, (50,10,) indica dos capas ocultas con 50 y 10 neuronas respectivamente; (50,10,20,) indica tres capas ocultas con 50, 10 y 20 neuronas respectivamente, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Construcción de un clasificador en una base de datos real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"pima_construccion.csv\", header=0, sep=',')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** Pregnancies: ** Number of times pregnant\n",
    "* ** Glucose: ** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* ** BloodPressure: ** Diastolic blood pressure (mm Hg)\n",
    "* ** SkinThickness: ** Triceps skin fold thickness (mm)\n",
    "* ** Insulin: ** 2-Hour serum insulin (mu U/ml)\n",
    "* ** BMI: ** Body mass index (weight in kg/(height in m)^2)\n",
    "* ** DiabetesPedigreeFunction: ** Diabetes pedigree function\n",
    "* ** Age: ** Age (years)\n",
    "* ** Class: ** Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Histogram Matrix Plot\n",
    "fig = df.hist(figsize=(20, 10))\n",
    "[x.title.set_size(18) for x in fig.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nombres_atrs = list(df.columns)\n",
    "nombres_atrs.remove('class')\n",
    "print(nombres_atrs)\n",
    "X = df[nombres_atrs].values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Histogramas suavizados con diferentes clases\n",
    "for n in nombres_atrs:\n",
    "    plt.figure(figsize=(3,2))\n",
    "    df.groupby(\"class\")[n].plot(kind='kde',\n",
    "                                title='Hist. de '+n)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo y chequeo de su calidad usando 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda entrena un modelo y lo evalúa en varias particiones training-test diferentes de los datos. El resultado es un score medio junto a su desviación estándar. El tipo de modelo (Naïve Bayes / árbol de decisión / knn/ regresión logística / red neuronal) y parámetros empleados deberán ser seleccionados para que dicho resultado sea el mejor posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"scores: \", scores)\n",
    "print(\"{:.2f} +/- {:.2f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste final del modelo usando todos los datos y predicción del conjunto de explotación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo seleccionado en la celda anterior se ajustará ahora usando todos los datos etiquetados disponibles, y se usará para predecir datos no etiquetados (base de datos de \"explotación\"). Se guardarán dichas predicciones en el archivo de predicciones de explotación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_explotacion = pd.read_csv(\"pima_explotacion.csv\", header=0, sep=',')\n",
    "df_explotacion.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_explotacion = df_explotacion[nombres_atrs].values\n",
    "predicciones = clf.predict(X_explotacion)\n",
    "\n",
    "f = open(\"predicciones_explotacion.txt\", \"w\")\n",
    "for pred in predicciones:\n",
    "    f.write(str(pred)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
